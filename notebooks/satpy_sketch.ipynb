{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "813e4a7c",
   "metadata": {},
   "source": [
    "#### Pre-processing I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7d95bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/cshatto/Projects/fire-recovery\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "# change wd\n",
    "os.chdir('..')\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eb4e027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "satpy version: 0.56.0\n"
     ]
    }
   ],
   "source": [
    "import satpy\n",
    "print(f\"satpy version: {satpy.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c212126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Readers\n",
      "=======\n",
      "generic_image:  ok\n",
      "msi_safe:  ok\n",
      "msi_safe_l2a:  ok\n",
      "\n",
      "Writers\n",
      "=======\n",
      "cf:  ok\n",
      "geotiff:  ok\n",
      "simple_image:  ok\n",
      "\n",
      "Versions\n",
      "======\n",
      "platform: macOS-15.4.1-arm64-arm-64bit-Mach-O\n",
      "python: 3.13.3\n",
      "\n",
      "cartopy: 0.24.1\n",
      "dask: 2025.5.0\n",
      "fsspec: 2025.3.2\n",
      "gdal: not installed\n",
      "geoviews: 1.14.0\n",
      "h5netcdf: 1.6.1\n",
      "h5py: 3.13.0\n",
      "netcdf4: 1.7.2\n",
      "numpy: 2.2.5\n",
      "pyhdf: 0.11.6\n",
      "pyproj: 3.7.1\n",
      "rasterio: 1.4.3\n",
      "xarray: 2025.1.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from satpy.utils import check_satpy\n",
    "# from satpy.utils import debug_on\n",
    "# debug_on()\n",
    "check_satpy(readers=['msi_safe_l2a', 'msi_safe', 'generic_image'],\n",
    "            writers=['geotiff', 'cf', 'simple_image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8432afc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdalinfo data/safe_rasters/S2A_MSIL2A_20240915T112111_N0511_R037_T29TNF_20240915T155449/S2A_MSIL2A_20240915T112111_N0511_R037_T29TNF_20240915T155449.SAFE/GRANULE/L2A_T29TNF_A048225_20240915T112112/IMG_DATA/R10m/T29TNF_20240915T112111_B02_10m.jp2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d641755c",
   "metadata": {},
   "source": [
    "collect safe files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d4a1cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from satpy.readers import find_files_and_readers\n",
    "# Get list of SAFE directories\n",
    "safe_dirs = glob(\"data/safe_rasters/*\")\n",
    "\n",
    "# Collect files for each SAFE directory\n",
    "scene_files = []\n",
    "for safe_dir in safe_dirs:\n",
    "    files = find_files_and_readers(base_dir=safe_dir, reader=\"msi_safe_l2a\")\n",
    "    scene_files.append(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aa867e",
   "metadata": {},
   "source": [
    "read safes into scenes and sort by start time, then load scenes into multiscene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb1d2688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cshatto/Projects/fire-recovery/venv/lib/python3.13/site-packages/satpy/readers/msi_safe.py:97: UserWarning: The specified chunks separate the stored chunks along dimension \"y\" starting at index 4096. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  proj = xr.open_dataset(self.filename, engine=\"rasterio\", chunks=CHUNK_SIZE)[\"band_data\"]\n",
      "/Users/cshatto/Projects/fire-recovery/venv/lib/python3.13/site-packages/satpy/readers/msi_safe.py:97: UserWarning: The specified chunks separate the stored chunks along dimension \"x\" starting at index 4096. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  proj = xr.open_dataset(self.filename, engine=\"rasterio\", chunks=CHUNK_SIZE)[\"band_data\"]\n",
      "/Users/cshatto/Projects/fire-recovery/venv/lib/python3.13/site-packages/satpy/readers/msi_safe.py:97: UserWarning: The specified chunks separate the stored chunks along dimension \"y\" starting at index 4096. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  proj = xr.open_dataset(self.filename, engine=\"rasterio\", chunks=CHUNK_SIZE)[\"band_data\"]\n",
      "/Users/cshatto/Projects/fire-recovery/venv/lib/python3.13/site-packages/satpy/readers/msi_safe.py:97: UserWarning: The specified chunks separate the stored chunks along dimension \"x\" starting at index 4096. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  proj = xr.open_dataset(self.filename, engine=\"rasterio\", chunks=CHUNK_SIZE)[\"band_data\"]\n",
      "The following datasets were not created and may require resampling to be generated: DataID(name='natural_color_l2a')\n",
      "/Users/cshatto/Projects/fire-recovery/venv/lib/python3.13/site-packages/satpy/readers/msi_safe.py:97: UserWarning: The specified chunks separate the stored chunks along dimension \"y\" starting at index 4096. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  proj = xr.open_dataset(self.filename, engine=\"rasterio\", chunks=CHUNK_SIZE)[\"band_data\"]\n",
      "/Users/cshatto/Projects/fire-recovery/venv/lib/python3.13/site-packages/satpy/readers/msi_safe.py:97: UserWarning: The specified chunks separate the stored chunks along dimension \"x\" starting at index 4096. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  proj = xr.open_dataset(self.filename, engine=\"rasterio\", chunks=CHUNK_SIZE)[\"band_data\"]\n",
      "/Users/cshatto/Projects/fire-recovery/venv/lib/python3.13/site-packages/satpy/readers/msi_safe.py:97: UserWarning: The specified chunks separate the stored chunks along dimension \"y\" starting at index 4096. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  proj = xr.open_dataset(self.filename, engine=\"rasterio\", chunks=CHUNK_SIZE)[\"band_data\"]\n",
      "/Users/cshatto/Projects/fire-recovery/venv/lib/python3.13/site-packages/satpy/readers/msi_safe.py:97: UserWarning: The specified chunks separate the stored chunks along dimension \"x\" starting at index 4096. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  proj = xr.open_dataset(self.filename, engine=\"rasterio\", chunks=CHUNK_SIZE)[\"band_data\"]\n",
      "The following datasets were not created and may require resampling to be generated: DataID(name='natural_color_l2a')\n",
      "/Users/cshatto/Projects/fire-recovery/venv/lib/python3.13/site-packages/satpy/readers/msi_safe.py:97: UserWarning: The specified chunks separate the stored chunks along dimension \"y\" starting at index 4096. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  proj = xr.open_dataset(self.filename, engine=\"rasterio\", chunks=CHUNK_SIZE)[\"band_data\"]\n",
      "/Users/cshatto/Projects/fire-recovery/venv/lib/python3.13/site-packages/satpy/readers/msi_safe.py:97: UserWarning: The specified chunks separate the stored chunks along dimension \"x\" starting at index 4096. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  proj = xr.open_dataset(self.filename, engine=\"rasterio\", chunks=CHUNK_SIZE)[\"band_data\"]\n",
      "/Users/cshatto/Projects/fire-recovery/venv/lib/python3.13/site-packages/satpy/readers/msi_safe.py:97: UserWarning: The specified chunks separate the stored chunks along dimension \"y\" starting at index 4096. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  proj = xr.open_dataset(self.filename, engine=\"rasterio\", chunks=CHUNK_SIZE)[\"band_data\"]\n",
      "/Users/cshatto/Projects/fire-recovery/venv/lib/python3.13/site-packages/satpy/readers/msi_safe.py:97: UserWarning: The specified chunks separate the stored chunks along dimension \"x\" starting at index 4096. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  proj = xr.open_dataset(self.filename, engine=\"rasterio\", chunks=CHUNK_SIZE)[\"band_data\"]\n",
      "The following datasets were not created and may require resampling to be generated: DataID(name='natural_color_l2a')\n",
      "/Users/cshatto/Projects/fire-recovery/venv/lib/python3.13/site-packages/satpy/readers/msi_safe.py:97: UserWarning: The specified chunks separate the stored chunks along dimension \"y\" starting at index 4096. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  proj = xr.open_dataset(self.filename, engine=\"rasterio\", chunks=CHUNK_SIZE)[\"band_data\"]\n",
      "/Users/cshatto/Projects/fire-recovery/venv/lib/python3.13/site-packages/satpy/readers/msi_safe.py:97: UserWarning: The specified chunks separate the stored chunks along dimension \"x\" starting at index 4096. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  proj = xr.open_dataset(self.filename, engine=\"rasterio\", chunks=CHUNK_SIZE)[\"band_data\"]\n",
      "/Users/cshatto/Projects/fire-recovery/venv/lib/python3.13/site-packages/satpy/readers/msi_safe.py:97: UserWarning: The specified chunks separate the stored chunks along dimension \"y\" starting at index 4096. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  proj = xr.open_dataset(self.filename, engine=\"rasterio\", chunks=CHUNK_SIZE)[\"band_data\"]\n",
      "/Users/cshatto/Projects/fire-recovery/venv/lib/python3.13/site-packages/satpy/readers/msi_safe.py:97: UserWarning: The specified chunks separate the stored chunks along dimension \"x\" starting at index 4096. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  proj = xr.open_dataset(self.filename, engine=\"rasterio\", chunks=CHUNK_SIZE)[\"band_data\"]\n",
      "The following datasets were not created and may require resampling to be generated: DataID(name='natural_color_l2a')\n",
      "/Users/cshatto/Projects/fire-recovery/venv/lib/python3.13/site-packages/satpy/readers/msi_safe.py:97: UserWarning: The specified chunks separate the stored chunks along dimension \"y\" starting at index 4096. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  proj = xr.open_dataset(self.filename, engine=\"rasterio\", chunks=CHUNK_SIZE)[\"band_data\"]\n",
      "/Users/cshatto/Projects/fire-recovery/venv/lib/python3.13/site-packages/satpy/readers/msi_safe.py:97: UserWarning: The specified chunks separate the stored chunks along dimension \"x\" starting at index 4096. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  proj = xr.open_dataset(self.filename, engine=\"rasterio\", chunks=CHUNK_SIZE)[\"band_data\"]\n",
      "/Users/cshatto/Projects/fire-recovery/venv/lib/python3.13/site-packages/satpy/readers/msi_safe.py:97: UserWarning: The specified chunks separate the stored chunks along dimension \"y\" starting at index 4096. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  proj = xr.open_dataset(self.filename, engine=\"rasterio\", chunks=CHUNK_SIZE)[\"band_data\"]\n",
      "/Users/cshatto/Projects/fire-recovery/venv/lib/python3.13/site-packages/satpy/readers/msi_safe.py:97: UserWarning: The specified chunks separate the stored chunks along dimension \"x\" starting at index 4096. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  proj = xr.open_dataset(self.filename, engine=\"rasterio\", chunks=CHUNK_SIZE)[\"band_data\"]\n",
      "The following datasets were not created and may require resampling to be generated: DataID(name='natural_color_l2a')\n",
      "/Users/cshatto/Projects/fire-recovery/venv/lib/python3.13/site-packages/satpy/readers/msi_safe.py:97: UserWarning: The specified chunks separate the stored chunks along dimension \"y\" starting at index 4096. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  proj = xr.open_dataset(self.filename, engine=\"rasterio\", chunks=CHUNK_SIZE)[\"band_data\"]\n",
      "/Users/cshatto/Projects/fire-recovery/venv/lib/python3.13/site-packages/satpy/readers/msi_safe.py:97: UserWarning: The specified chunks separate the stored chunks along dimension \"x\" starting at index 4096. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  proj = xr.open_dataset(self.filename, engine=\"rasterio\", chunks=CHUNK_SIZE)[\"band_data\"]\n",
      "/Users/cshatto/Projects/fire-recovery/venv/lib/python3.13/site-packages/satpy/readers/msi_safe.py:97: UserWarning: The specified chunks separate the stored chunks along dimension \"y\" starting at index 4096. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  proj = xr.open_dataset(self.filename, engine=\"rasterio\", chunks=CHUNK_SIZE)[\"band_data\"]\n",
      "/Users/cshatto/Projects/fire-recovery/venv/lib/python3.13/site-packages/satpy/readers/msi_safe.py:97: UserWarning: The specified chunks separate the stored chunks along dimension \"x\" starting at index 4096. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  proj = xr.open_dataset(self.filename, engine=\"rasterio\", chunks=CHUNK_SIZE)[\"band_data\"]\n",
      "The following datasets were not created and may require resampling to be generated: DataID(name='natural_color_l2a')\n",
      "/Users/cshatto/Projects/fire-recovery/venv/lib/python3.13/site-packages/satpy/readers/msi_safe.py:97: UserWarning: The specified chunks separate the stored chunks along dimension \"y\" starting at index 4096. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  proj = xr.open_dataset(self.filename, engine=\"rasterio\", chunks=CHUNK_SIZE)[\"band_data\"]\n",
      "/Users/cshatto/Projects/fire-recovery/venv/lib/python3.13/site-packages/satpy/readers/msi_safe.py:97: UserWarning: The specified chunks separate the stored chunks along dimension \"x\" starting at index 4096. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  proj = xr.open_dataset(self.filename, engine=\"rasterio\", chunks=CHUNK_SIZE)[\"band_data\"]\n",
      "/Users/cshatto/Projects/fire-recovery/venv/lib/python3.13/site-packages/satpy/readers/msi_safe.py:97: UserWarning: The specified chunks separate the stored chunks along dimension \"y\" starting at index 4096. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  proj = xr.open_dataset(self.filename, engine=\"rasterio\", chunks=CHUNK_SIZE)[\"band_data\"]\n",
      "/Users/cshatto/Projects/fire-recovery/venv/lib/python3.13/site-packages/satpy/readers/msi_safe.py:97: UserWarning: The specified chunks separate the stored chunks along dimension \"x\" starting at index 4096. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  proj = xr.open_dataset(self.filename, engine=\"rasterio\", chunks=CHUNK_SIZE)[\"band_data\"]\n",
      "The following datasets were not created and may require resampling to be generated: DataID(name='natural_color_l2a')\n",
      "/Users/cshatto/Projects/fire-recovery/venv/lib/python3.13/site-packages/satpy/readers/msi_safe.py:97: UserWarning: The specified chunks separate the stored chunks along dimension \"y\" starting at index 4096. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  proj = xr.open_dataset(self.filename, engine=\"rasterio\", chunks=CHUNK_SIZE)[\"band_data\"]\n",
      "/Users/cshatto/Projects/fire-recovery/venv/lib/python3.13/site-packages/satpy/readers/msi_safe.py:97: UserWarning: The specified chunks separate the stored chunks along dimension \"x\" starting at index 4096. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  proj = xr.open_dataset(self.filename, engine=\"rasterio\", chunks=CHUNK_SIZE)[\"band_data\"]\n",
      "/Users/cshatto/Projects/fire-recovery/venv/lib/python3.13/site-packages/satpy/readers/msi_safe.py:97: UserWarning: The specified chunks separate the stored chunks along dimension \"y\" starting at index 4096. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  proj = xr.open_dataset(self.filename, engine=\"rasterio\", chunks=CHUNK_SIZE)[\"band_data\"]\n",
      "/Users/cshatto/Projects/fire-recovery/venv/lib/python3.13/site-packages/satpy/readers/msi_safe.py:97: UserWarning: The specified chunks separate the stored chunks along dimension \"x\" starting at index 4096. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  proj = xr.open_dataset(self.filename, engine=\"rasterio\", chunks=CHUNK_SIZE)[\"band_data\"]\n",
      "The following datasets were not created and may require resampling to be generated: DataID(name='natural_color_l2a')\n"
     ]
    }
   ],
   "source": [
    "from satpy import Scene\n",
    "scenes = []\n",
    "for files in scene_files:\n",
    "    scn = Scene(reader=\"msi_safe_l2a\", filenames=files)\n",
    "    scn.load([\"B04\",\"B08\",\"B12\",\"ndvi_l2a\", \"natural_color_l2a\"],calibration=\"reflectance\") \n",
    "    scenes.append(scn)\n",
    "scenes = sorted(scenes, key=lambda scn: scn.start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a633c147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from satpy import MultiScene\n",
    "mscn = MultiScene(scenes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e475da0",
   "metadata": {},
   "source": [
    "#### Bounding box, location of fires in Portugal\n",
    "- South West: 41.06626째, -8.24721째\n",
    "- North East: 41.48443째, -7.48991째"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc79a10",
   "metadata": {},
   "source": [
    "resample multiscene to area of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18372bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyresample.geometry import AreaDefinition\n",
    "\n",
    "# challenge info\n",
    "area_id = \"northern_portugal\"\n",
    "description = \"Northern Portugal region\"\n",
    "proj_id = \"latlong\"\n",
    "projection = {\"proj\": \"latlong\", \"datum\": \"WGS84\"}\n",
    "width = 1000\n",
    "height = 1000\n",
    "area_extent = (-8.24721, 41.06626, -7.48991, 41.48443)  # South West to North East\n",
    "area_def = AreaDefinition(area_id, description, proj_id, projection, width, height, area_extent)\n",
    "\n",
    "# Resample images to same grid and resolution\n",
    "mscn = mscn.resample(area_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcba79ee",
   "metadata": {},
   "source": [
    "group (mosaic) neighboring tiles together by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fc3e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "# Group scenes by date (1-day threshold) and mosaic\n",
    "threshold = timedelta(days=1)\n",
    "mosaicked_scenes = []\n",
    "scenes = list(mscn.scenes)\n",
    "while scenes:\n",
    "    group = [scenes[0]]\n",
    "    ref_time = scenes[0].start_time\n",
    "    for s in scenes[1:]:\n",
    "        if abs(s.start_time - ref_time) <= threshold:\n",
    "            group.append(s)\n",
    "    for s in group:\n",
    "        scenes.remove(s)\n",
    "    # Mosaic tiles in the group into a single Scene\n",
    "    group_mscn = MultiScene(group)\n",
    "    blended = group_mscn.blend()  # Default stack mosaics tiles\n",
    "    mosaicked_scenes.append(blended)\n",
    "\n",
    "mscn = MultiScene(mosaicked_scenes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07c9d96",
   "metadata": {},
   "source": [
    "calculate nbr and ndvi, then clip to valid index ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d4e6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for scene in mscn.scenes:\n",
    "    b08 = scene['B08'].compute()\n",
    "    b12 = scene['B12'].compute()\n",
    "    nbr = (b08 - b12) / (b08 + b12 + 1e-10)    \n",
    "    nbr = np.clip(nbr, -1, 1)\n",
    "    nbr.attrs = scene['B08'].attrs\n",
    "    ndvi = scene['ndvi_l2a'].compute()\n",
    "    ndvi = np.clip(ndvi, -1, 1)\n",
    "    ndvi.attrs = scene['B08'].attrs\n",
    "    scene['ndvi'] = ndvi\n",
    "    scene['nbr'] = nbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65415187",
   "metadata": {},
   "outputs": [],
   "source": [
    "mscn.scenes[1].show('ndvi_l2a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c58053",
   "metadata": {},
   "outputs": [],
   "source": [
    "mscn.scenes[1]['ndvi_l2a'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d882cfb1",
   "metadata": {},
   "source": [
    "fun mp4 animation from satpy package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0e1a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mscn.save_animation('data/output/satpy_animations/{name}_{start_time:%Y%m%d_%H%M%S}.mp4', fps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a888e18c",
   "metadata": {},
   "source": [
    "save to geotiffs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00703624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO preserve float32 values\n",
    "for scene in mscn.scenes:\n",
    "    safe_name = f\"S2A_MSIL2A_{scene.start_time.strftime('%Y%m%dT%H%M%S')}\"    \n",
    "    for dataset in ['natural_color_l2a', 'ndvi', 'nbr']:\n",
    "        scene.save_dataset(\n",
    "            dataset,\n",
    "            writer='geotiff',\n",
    "            filename=f\"data/satpy_geotiffs/{safe_name}_{dataset}.tif\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bf57b5",
   "metadata": {},
   "source": [
    "#### Preprocessing II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47beb77",
   "metadata": {},
   "source": [
    "dnbr vectorization of BAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac3a53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_pre, scene_post = list(mscn.scenes)[:2]\n",
    "\n",
    "# Compute dNBR (NBR_pre - NBR_post)\n",
    "nbr_pre = scene_pre['nbr'].compute()\n",
    "nbr_post = scene_post['nbr'].compute()\n",
    "dnbr = nbr_pre - nbr_post\n",
    "dnbr.attrs = scene_pre['nbr'].attrs\n",
    "scene_post['dnbr'] = dnbr.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e31d5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_mask = (dnbr >= 0.3).astype('uint8') # could be higher for severe fires but will do pix count later\n",
    "ba_mask.attrs = scene_post.attrs\n",
    "scene_post['ba_mask'] = ba_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bfa624",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_post.show('ba_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3263c64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import label\n",
    "# Identify connected clusters and filter by size, 150 is best sofar\n",
    "structure = np.ones((3, 3), dtype=np.uint8)  \n",
    "labeled_array, num_features = label(ba_mask.values, structure=structure)\n",
    "filtered_mask = np.zeros_like(labeled_array, dtype=np.uint8)\n",
    "if num_features > 0:\n",
    "    for i in range(1, num_features + 1):\n",
    "        cluster_size = np.sum(labeled_array == i)\n",
    "        if cluster_size > 150:  \n",
    "            filtered_mask[labeled_array == i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5852d0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_mask_filtered = xr.DataArray(\n",
    "    filtered_mask,\n",
    "    coords=ba_mask.coords,\n",
    "    dims=ba_mask.dims,\n",
    "    attrs=ba_mask.attrs\n",
    ").astype('uint8')\n",
    "scene_post['ba_mask'] = ba_mask_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74df111c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_post.show('ba_mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b11d8cb",
   "metadata": {},
   "source": [
    "vectorize recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31babd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray\n",
    "from rasterio.features import shapes\n",
    "from shapely.geometry import shape\n",
    "\n",
    "#temp file just for vectorization\n",
    "temp_tif = 'temp_ba_mask.tif'\n",
    "scene_post['ba_mask'].rio.to_raster(temp_tif, driver='GTiff')\n",
    "\n",
    "#vectorize mask using rasterio shapes combined with shapley shape\n",
    "with rioxarray.open_rasterio(temp_tif) as src:\n",
    "    mask_data = src.squeeze().values\n",
    "    transform = src.rio.transform()\n",
    "    crs = src.rio.crs\n",
    "    shapes_gen = shapes(mask_data, mask=mask_data == 1, transform=transform)\n",
    "    polygons = [shape(geom) for geom, value in shapes_gen if value == 1]\n",
    "\n",
    "# Save \n",
    "ba = MultiPolygon(polygons) if polygons else MultiPolygon()\n",
    "gdf = gpd.GeoDataFrame(geometry=[ba], crs=crs)\n",
    "gdf.to_file('data/output/burn_areas.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba1f707",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea3e9d3",
   "metadata": {},
   "source": [
    "#### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5831f1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "from rasterio.features import shapes\n",
    "from shapely.geometry import shape, MultiPolygon\n",
    "import geopandas as gpd\n",
    "import os\n",
    "\n",
    "# Scenes: 2024-09-30 (1), 2024-11-09 (2), 2025-04-23 (3)\n",
    "scene_sept, scene_nov, scene_apr = mscn.scenes[1:4]\n",
    "\n",
    "# Load NDVI and mask\n",
    "for scene in [scene_sept, scene_nov, scene_apr]:\n",
    "    scene.load(['ndvi'])\n",
    "ndvi_sept = scene_sept['ndvi'].compute()\n",
    "ndvi_nov = scene_nov['ndvi'].compute()\n",
    "ndvi_apr = scene_apr['ndvi'].compute()\n",
    "ba_mask = scene_sept['ba_mask'].compute()\n",
    "\n",
    "# 2024-11-09 dNDVI\n",
    "scene_nov['dndvi'] = (ndvi_nov - ndvi_sept).where(ba_mask == 1, np.nan)\n",
    "scene_nov['recovery_mask'] = xr.where(ba_mask == 1, np.select(\n",
    "    [scene_nov['dndvi'] < 0.1, scene_nov['dndvi'] < 0.4, scene_nov['dndvi'] >= 0.4],\n",
    "    [1, 2, 3], 0\n",
    "), 0).astype('uint8')\n",
    "\n",
    "# 2025-04-23 dNDVI\n",
    "scene_apr['dndvi'] = (ndvi_apr - ndvi_sept).where(ba_mask == 1, np.nan)\n",
    "scene_apr['recovery_mask'] = xr.where(ba_mask == 1, np.select(\n",
    "    [scene_apr['dndvi'] < 0.1, scene_apr['dndvi'] < 0.4, scene_apr['dndvi'] >= 0.4],\n",
    "    [1, 2, 3], 0\n",
    "), 0).astype('uint8')\n",
    "\n",
    "# Vectorize and save\n",
    "for scene, date in [(scene_nov, '20241109'), (scene_apr, '20250423')]:\n",
    "    temp_tif = f'temp_recovery_{date}.tif'\n",
    "    scene['recovery_mask'].rio.to_raster(temp_tif)\n",
    "    with rioxarray.open_rasterio(temp_tif) as src:\n",
    "        mask_data = src.squeeze().values\n",
    "        transform = src.rio.transform()\n",
    "        polygons = [\n",
    "            {'geometry': shape(geom), 'recovery': {1: 'No Recovery', 2: 'Moderate Recovery', 3: 'High Recovery'}[val]}\n",
    "            for val in [1, 2, 3] for geom, val in shapes(mask_data, mask=mask_data == val, transform=transform)\n",
    "            if shape(geom).is_valid\n",
    "        ]\n",
    "    gdf = gpd.GeoDataFrame(polygons, crs='EPSG:4326')\n",
    "    gdf.to_file(f'data/output/classification/recovery_areas_{date}.geojson') if not gdf.empty else gpd.GeoDataFrame(geometry=[shape(MultiPolygon())], crs='EPSG:4326').to_file(f'data/output/classification/recovery_areas_{date}.geojson')\n",
    "    os.remove(temp_tif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3dba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "mscn.scenes[2].show('dndvi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26e8cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from rasterio.features import shapes\n",
    "from shapely.geometry import shape\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "scene_sept, scene_nov, scene_apr = mscn.scenes[1:4]\n",
    "\n",
    "colors = {1: '#FF0000CC', 2: '#FFFF00CC', 3: '#00FF00CC'}\n",
    "labels = {1: 'No recovery', 2: 'Moderate recovery', 3: 'High recovery'}\n",
    "\n",
    "def vectorize_recovery(scene):\n",
    "    mask_data = scene['recovery_mask'].values\n",
    "    transform = scene['recovery_mask'].rio.transform()\n",
    "    crs = scene['recovery_mask'].rio.crs\n",
    "    polygons = [\n",
    "        {'geometry': shape(geom), 'recovery': val}\n",
    "        for val in [1, 2, 3] for geom, val in shapes(mask_data, mask=mask_data == val, transform=transform)\n",
    "        if shape(geom).is_valid\n",
    "    ]\n",
    "    return gpd.GeoDataFrame(polygons, crs=crs) if polygons else gpd.GeoDataFrame(geometry=[], crs=crs)\n",
    "\n",
    "def plot_bar_chart(gdf, date, labels):\n",
    "    gdf['area_ha'] = gdf.geometry.area / 10000\n",
    "    areas = gdf.groupby('recovery')['area_ha'].sum().reindex([1, 2, 3], fill_value=0)\n",
    "    df = pd.DataFrame({\n",
    "        'Recovery': [labels.get(i, 'Unknown') for i in [1, 2, 3]],\n",
    "        'Area (ha)': areas.values\n",
    "    })\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.barplot(data=df, x='Recovery', y='Area (ha)', palette=[colors[i] for i in [1, 2, 3]])\n",
    "    plt.title(f'Recovery Areas - {date}', fontsize=14)\n",
    "    plt.xlabel('Recovery Class', fontsize=12)\n",
    "    plt.ylabel('Area (hectares)', fontsize=12)\n",
    "    plt.savefig(f'data/output/classification/recovery_bar_{date}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "for scene, date in [(scene_nov, '20241109'), (scene_apr, '20250423')]:\n",
    "    gdf = vectorize_recovery(scene)\n",
    "    plot_bar_chart(gdf, date, labels)\n",
    "\n",
    "print(f\"ba_mask_filtered pixels={scene_sept['ba_mask_filtered'].sum().values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a00dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium.features import GeoJson, GeoJsonTooltip\n",
    "import pandas as pd\n",
    "\n",
    "# Load GeoDataFrames\n",
    "try:\n",
    "    gdf_20241109 = gpd.read_file('data/output/classification/recovery_areas_20241109.geojson')\n",
    "    gdf_20250423 = gpd.read_file('data/output/classification/recovery_areas_20250423.geojson')\n",
    "except Exception as e:\n",
    "    print(f\"Error loading gdfs: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Ensure CRS is EPSG:4326\n",
    "if gdf_20241109.crs != \"EPSG:4326\":\n",
    "    gdf_20241109 = gdf_20241109.to_crs(\"EPSG:4326\")\n",
    "if gdf_20250423.crs != \"EPSG:4326\":\n",
    "    gdf_20250423 = gdf_20250423.to_crs(\"EPSG:4326\")\n",
    "\n",
    "# Validate geometries\n",
    "gdf_20241109 = gdf_20241109[gdf_20241109.geometry.is_valid]\n",
    "gdf_20250423 = gdf_20250423[gdf_20250423.geometry.is_valid]\n",
    "print(f\"Valid features after filtering (2024-11-09): {len(gdf_20241109)}\")\n",
    "print(f\"Valid features after filtering (2025-04-23): {len(gdf_20250423)}\")\n",
    "\n",
    "# Exit if no valid features\n",
    "if len(gdf_20241109) == 0 or len(gdf_20250423) == 0:\n",
    "    print(\"Error: One or both GeoDataFrames are empty after validation.\")\n",
    "    exit()\n",
    "\n",
    "# Prepare recovery columns\n",
    "gdf_20241109['recovery_20241109'] = gdf_20241109.get('recovery', 'unknown').astype(str).replace('nan', 'unknown')\n",
    "gdf_20250423['recovery_20250423'] = gdf_20250423.get('recovery', 'unknown').astype(str).replace('nan', 'unknown')\n",
    "\n",
    "# Define color mapping\n",
    "colors = {\n",
    "    'No Recovery': '#FF0000CC',      # Red\n",
    "    'Moderate Recovery': '#FFFF00CC', # Yellow\n",
    "    'High Recovery': '#00FF00CC',     # Green\n",
    "    'unknown': '#808080CC'   # Gray for missing/unknown\n",
    "}\n",
    "\n",
    "# Create Folium map\n",
    "m = folium.Map(\n",
    "    location=[(41.07 + 41.48) / 2, (-8.247 + -7.49) / 2],\n",
    "    zoom_start=10,\n",
    "    tiles='CartoDB positron',\n",
    "    name='Light Basemap'\n",
    ")\n",
    "\n",
    "# Add satellite imagery layer\n",
    "folium.TileLayer(\n",
    "    tiles='https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
    "    attr='Esri',\n",
    "    name='Satellite Imagery'\n",
    ").add_to(m)\n",
    "\n",
    "# Style functions\n",
    "def style_nov(feature):\n",
    "    recovery = feature['properties'].get('recovery_20241109', 'unknown')\n",
    "    return {\n",
    "        'fillColor': colors.get(recovery, '#00000080'),  # Default to black if value not in colors\n",
    "        'color': 'black',\n",
    "        'weight': 0,\n",
    "        'fillOpacity': 0.6\n",
    "    }\n",
    "\n",
    "def style_apr(feature):\n",
    "    recovery = feature['properties'].get('recovery_20250423', 'unknown')\n",
    "    return {\n",
    "        'fillColor': colors.get(recovery, '#00000080'),  # Default to black if value not in colors\n",
    "        'color': 'black',\n",
    "        'weight': 0,\n",
    "        'fillOpacity': 0.6\n",
    "    }\n",
    "\n",
    "# Tooltips\n",
    "tooltip_nov = folium.GeoJsonTooltip(\n",
    "    fields=[\"recovery_20241109\"],\n",
    "    aliases=[\"2024-11-09\"],\n",
    "    labels=True,\n",
    "    sticky=True,\n",
    "    localize=True,\n",
    "    style=\"font-size: 14px; font-weight: bold;\"\n",
    ")\n",
    "\n",
    "tooltip_apr = folium.GeoJsonTooltip(\n",
    "    fields=[\"recovery_20250423\"],\n",
    "    aliases=[\"2025-04-23\"],\n",
    "    labels=True,\n",
    "    sticky=True,\n",
    "    localize=True,\n",
    "    style=\"font-size: 14px; font-weight: bold;\"\n",
    ")\n",
    "\n",
    "# Add GeoJSON layers\n",
    "folium.GeoJson(\n",
    "    gdf_20241109,\n",
    "    style_function=style_nov,\n",
    "    tooltip=tooltip_nov,\n",
    "    name='Recovery 2024-11-09'\n",
    ").add_to(m)\n",
    "\n",
    "folium.GeoJson(\n",
    "    gdf_20250423,\n",
    "    style_function=style_apr,\n",
    "    tooltip=tooltip_apr,\n",
    "    name='Recovery 2025-04-23'\n",
    ").add_to(m)\n",
    "\n",
    "# Add layer control\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "# Save map\n",
    "m.save('data/output/classification/recovery_map.html')\n",
    "print(\"Folium map saved as 'recovery_map.html'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
